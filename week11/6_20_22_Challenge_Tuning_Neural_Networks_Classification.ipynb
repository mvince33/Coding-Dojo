{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mvince33/Coding-Dojo/blob/main/week11/6_20_22_Challenge_Tuning_Neural_Networks_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGKAZlCh02cl"
      },
      "source": [
        "# Tuning Neural Networking in Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OStduN-207_9"
      },
      "source": [
        "We will use the version of Keras that comes in the Tensorflow package, as it has the most up to date tools."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zw6CH1mp0zR4"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from seaborn import heatmap\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, classification_report, ConfusionMatrixDisplay\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# New libraries\n",
        "import tensorflow.keras as keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_classification(y_true, y_pred, labels=None, normalize=None):\n",
        "  print(classification_report(y_true, y_pred, target_names=labels))\n",
        "\n",
        "  ConfusionMatrixDisplay.from_predictions(y_true, y_pred,\n",
        "                                          display_labels=labels, \n",
        "                                          normalize=normalize,\n",
        "                                          cmap='Blues')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "IiMn7tOFIF6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5pga5rHChPu"
      },
      "source": [
        "### Plot History\n",
        "\n",
        "Since we will be plotting histories for all of our models, lets create a function to do it quickly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbrKqMv0_28Q"
      },
      "source": [
        "#  You can use this function to see how your model improves over time\n",
        "def plot_history(history, metrics=None):\n",
        "  plt.plot(history.history['loss'], label='training')\n",
        "  plt.plot(history.history['val_loss'], label='testing')\n",
        "  plt.title('Loss')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  if metrics:\n",
        "    for metric in metrics:\n",
        "      plt.plot(history.history[metric], label=f'training {metric}')\n",
        "      plt.plot(history.history[f'val_{metric}'], label=f'testing {metric}')\n",
        "      plt.legend()\n",
        "      plt.title(metric)\n",
        "      plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWaTq6c7FHlr"
      },
      "source": [
        "\n",
        "# Classification:\n",
        "\n",
        "Classification models are similar, except that we need to adjust the final activation of the output layer, the loss function in the compile step, and the metrics we use to judge them.  Remember: MAE, MSE, RMSE, and R2 are regression metrics, accuracy, recall, precision, F1-Score, and confusion matrices are classification metrics.\n",
        "\n",
        "## Classification Dataset\n",
        "The classification dataset describes diabetes rates among Pima Indians.  Each row is a person and this dataset and includes features regarding health related measurements.  The target binary and represents whether or not a person will diagnosed with diabetes.  This is another old dataset first presented in 1988.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CN1zHoGcGeFN"
      },
      "source": [
        "classification_df = pd.read_csv('https://raw.githubusercontent.com/ninja-josh/image-storage/main/diabetes.csv')\n",
        "classification_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isTaHNFpGjQH"
      },
      "source": [
        "classification_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtZv-V73Gmjv"
      },
      "source": [
        "classification_df.duplicated().any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdF3qT-9Gp_s"
      },
      "source": [
        "classification_df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8cjiy3BGvLa"
      },
      "source": [
        "We see minimums for Glucose, BloodPressure, SkinThickness, Insulin, and BMI of 0s.  Those are impossible for humans, so lets drop those rows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwzoeFVWG6Dd"
      },
      "source": [
        "no_glucose = classification_df['Glucose'] == 0\n",
        "no_blood = classification_df['BloodPressure'] == 0\n",
        "no_skin = classification_df['SkinThickness'] == 0\n",
        "no_insulin = classification_df['Insulin'] == 0\n",
        "no_bmi = classification_df['BMI'] == 0\n",
        "\n",
        "#class_df_clean excludes rows that have no values == 0 in the above columns\n",
        "class_df_clean = classification_df[~(no_glucose |\n",
        "                                     no_blood |\n",
        "                                     no_skin |\n",
        "                                     no_insulin |\n",
        "                                     no_bmi)]\n",
        "class_df_clean.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQqWsTbaM5It"
      },
      "source": [
        "We lost a lot of data, going from 768 samples to 392 samples.  In the future we might impute this data using means, medians, or other imputation strategies.  For this exercise we won't focus on that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjREwrWgGPtP"
      },
      "source": [
        "# Define X and y and train test split\n",
        "X = class_df_clean.drop(columns = 'Outcome')\n",
        "y = class_df_clean['Outcome']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, stratify = y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKPiCOByPOfF"
      },
      "source": [
        "# Scale\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build your model"
      ],
      "metadata": {
        "id": "-KjQU7IgB7W1"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAwy3AXrPjwH"
      },
      "source": [
        "# Build your model\n",
        "\n",
        "n_cols = X_train.shape[1]\n",
        "\n",
        "# Instentiate the model\n",
        "class_model = Sequential()\n",
        "\n",
        "# create the first layer with input as the no of features in dataset\n",
        "class_model.add(Dense(10, activation = 'relu', input_dim = X_train.shape[1]))\n",
        "\n",
        "# Create hidden layers\n",
        "class_model.add(Dense(10, activation = 'relu'))\n",
        "\n",
        "# Create output layer \n",
        "# Since this is a binary classification, the activation function of our final layer needs to be 'sigmoid'. \n",
        "\n",
        "class_model.add(Dense(1, activation = 'sigmoid'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOe9CMP2PtDT"
      },
      "source": [
        "# Compile your model\n",
        "\n",
        "# Since this is binary classification set loss  = 'binary_crossentropy'\n",
        "# Set the metrics = ['acc']\n",
        "class_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['acc'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vScTvfoKOVLO"
      },
      "source": [
        "# fit your model\n",
        "history = class_model.fit(X_train, y_train,\n",
        "                        validation_data = (X_test, y_test),\n",
        "                        epochs = 100)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKLxgYDcP0_H"
      },
      "source": [
        "# See how your model is doing\n",
        "plot_history(history, metrics = ['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LD18RKjYTFXP"
      },
      "source": [
        "## Evaluation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRFdGfPeXGvt"
      },
      "source": [
        "# Make predicitons and evaluate your model\n",
        "# Define labels for the confusion matrix\n",
        "labels = ['No Diabetes', 'Diabetes']\n",
        "\n",
        "# Get predictions and round them to integers instead of floats\n",
        "train_preds = np.rint(class_model.predict(X_train))\n",
        "test_preds = np.rint(class_model.predict(X_test))\n",
        "\n",
        "# Evaluate training set\n",
        "print('Training Evaluation:\\n')\n",
        "evaluate_classification(y_train, train_preds, labels=labels,\n",
        "                        normalize='true')\n",
        "print('Testing Evaluation:\\n')\n",
        "# Confusion Matrix\n",
        "evaluate_classification(y_test, test_preds, labels=labels,\n",
        "                        normalize='true')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ‘‰ Tuning an underfit model:\n",
        "##Increase model complexity:\n",
        "1. add layers  \n",
        "2. add nodes \n",
        "3. reduce other regularization\n",
        "\n",
        "# ðŸ‘‰ Tuning an overfit model:\n",
        "## Reduce model complexity:\n",
        "1. Reduce layers or nodes\n",
        "2. Add dropout layers\n",
        "3. Implement early stopping callback\n",
        "3. Add L1 or L2 regularization\n",
        "\n",
        "\n",
        "# ðŸ”§ Your Turn: Tune This Model!\n",
        "\n",
        "* Choose one or more regularization techniques to improve this model.\n",
        "\n",
        "* Make one change at a time.  Make a new cell for each change to keep a record of what you've tried.\n",
        "\n",
        "##Ask yourselves:  Should we increase or decrease model complexity?\n",
        "\n"
      ],
      "metadata": {
        "id": "gPJ_ZkIx7FL6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NwfdoXN3I4Xg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g2UjMFIBNmO8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}